{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n%pip install accelerate peft bitsandbytes transformers langchain langchain_community langchain_huggingface nest_asyncio faiss-gpu\n","metadata":{"execution":{"iopub.status.busy":"2024-07-19T03:38:43.598215Z","iopub.execute_input":"2024-07-19T03:38:43.599044Z","iopub.status.idle":"2024-07-19T03:39:10.353581Z","shell.execute_reply.started":"2024-07-19T03:38:43.599010Z","shell.execute_reply":"2024-07-19T03:39:10.352560Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import os\nimport torch\nimport bitsandbytes\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    TrainingArguments,\n    pipeline,\n    logging,\n)\nfrom peft import LoraConfig","metadata":{"execution":{"iopub.status.busy":"2024-07-19T03:39:35.387819Z","iopub.execute_input":"2024-07-19T03:39:35.388172Z","iopub.status.idle":"2024-07-19T03:39:54.600564Z","shell.execute_reply.started":"2024-07-19T03:39:35.388141Z","shell.execute_reply":"2024-07-19T03:39:54.599538Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-07-19 03:39:43.310505: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-19 03:39:43.310626: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-19 03:39:43.453279: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import BitsAndBytesConfig\nfrom huggingface_hub import login\n\nfrom langchain.text_splitter import CharacterTextSplitter\nfrom langchain_community.document_loaders import TextLoader\n\nfrom langchain_community.embeddings.huggingface import HuggingFaceEmbeddings\nfrom langchain_community.vectorstores import FAISS\n\nfrom langchain.prompts import PromptTemplate\nfrom langchain.schema.runnable import RunnablePassthrough\nfrom langchain.chains import LLMChain\nfrom langchain_huggingface import HuggingFacePipeline\n\nimport nest_asyncio","metadata":{"execution":{"iopub.status.busy":"2024-07-19T03:40:03.237732Z","iopub.execute_input":"2024-07-19T03:40:03.238376Z","iopub.status.idle":"2024-07-19T03:40:03.836068Z","shell.execute_reply.started":"2024-07-19T03:40:03.238343Z","shell.execute_reply":"2024-07-19T03:40:03.835140Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import login","metadata":{"execution":{"iopub.status.busy":"2024-07-19T03:40:08.899975Z","iopub.execute_input":"2024-07-19T03:40:08.900605Z","iopub.status.idle":"2024-07-19T03:40:08.904416Z","shell.execute_reply.started":"2024-07-19T03:40:08.900574Z","shell.execute_reply":"2024-07-19T03:40:08.903556Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nhug_token = user_secrets.get_secret(\"huggingface_token\")","metadata":{"execution":{"iopub.status.busy":"2024-07-19T03:40:10.508584Z","iopub.execute_input":"2024-07-19T03:40:10.509388Z","iopub.status.idle":"2024-07-19T03:40:10.767236Z","shell.execute_reply.started":"2024-07-19T03:40:10.509356Z","shell.execute_reply":"2024-07-19T03:40:10.766515Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"login(token=hug_token)","metadata":{"execution":{"iopub.status.busy":"2024-07-19T03:40:14.234167Z","iopub.execute_input":"2024-07-19T03:40:14.234509Z","iopub.status.idle":"2024-07-19T03:40:14.363766Z","shell.execute_reply.started":"2024-07-19T03:40:14.234484Z","shell.execute_reply":"2024-07-19T03:40:14.362730Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"compute_dtype = getattr(torch, \"float16\")\n\nquant_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=compute_dtype,\n    bnb_4bit_use_double_quant=False,\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-19T03:40:17.375099Z","iopub.execute_input":"2024-07-19T03:40:17.375779Z","iopub.status.idle":"2024-07-19T03:40:17.381545Z","shell.execute_reply.started":"2024-07-19T03:40:17.375747Z","shell.execute_reply":"2024-07-19T03:40:17.380598Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"base_model = 'meta-llama/Meta-Llama-Guard-2-8B'\nmodel = AutoModelForCausalLM.from_pretrained(\n    base_model,\n    quantization_config=quant_config,\n    device_map={\"\": 0}\n)\nmodel.config.use_cache = False\nmodel.config.pretraining_tp = 1","metadata":{"execution":{"iopub.status.busy":"2024-07-19T03:40:20.636218Z","iopub.execute_input":"2024-07-19T03:40:20.636628Z","iopub.status.idle":"2024-07-19T03:42:36.226248Z","shell.execute_reply.started":"2024-07-19T03:40:20.636599Z","shell.execute_reply":"2024-07-19T03:42:36.225556Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/654 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7702e34d244444d0a4d5c44e37c8f1b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9779f0046bc44a53810157e6501c0d0a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"211a3b47769948bd81c7e787033d10e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b731e262aa5b45a5b1de5d2b68b9e4af"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21354fc2edd447f3924b366f4598b638"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b839bd5f3bcc4116a854252011db9df1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa50c73867604f4190868a78e824296c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e517bce7247644f2b7603f4e85d9d689"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/126 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99d947f04d30470f9e5dbf37baf70d26"}},"metadata":{}}]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(base_model)","metadata":{"execution":{"iopub.status.busy":"2024-07-19T03:44:29.440549Z","iopub.execute_input":"2024-07-19T03:44:29.440939Z","iopub.status.idle":"2024-07-19T03:44:31.038067Z","shell.execute_reply.started":"2024-07-19T03:44:29.440908Z","shell.execute_reply":"2024-07-19T03:44:31.037012Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/51.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f65f84bbca34250a1d118da8bc6d611"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1fe9f45ccf534df59a9f6e2c0b672f08"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88ffa3f5d779460e9246d73fb6fe24d1"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Function to generate text based on the input question and context\ndef generate_text(question, context):\n    # Define the prompt template with the new instruction\n    prompt_template = (f\"Context: {context}\\n\"\n                       f\"Question: {question}\\n\"\n                       \"Please generate the answer to the question based on the context provided which is the retrieved data.\\n\"\n                       \"Answer:\")\n    \n    # Tokenize the input prompt\n    inputs = tokenizer(prompt_template, return_tensors=\"pt\")\n    \n    # Generate the output using the model\n    output = model.generate(**inputs, max_length=1000, num_return_sequences=1)\n    #output = model.generate(**inputs, num_return_sequences=1)\n    \n    # Decode the generated text\n    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n    \n    # Extract and return the generated answer (everything after 'Answer:')\n    answer = generated_text.split(\"Answer:\")[1].strip()\n    #print(answer)\n    return answer","metadata":{"execution":{"iopub.status.busy":"2024-07-19T03:44:36.359856Z","iopub.execute_input":"2024-07-19T03:44:36.360561Z","iopub.status.idle":"2024-07-19T03:44:36.366574Z","shell.execute_reply.started":"2024-07-19T03:44:36.360532Z","shell.execute_reply":"2024-07-19T03:44:36.365621Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Example usage\nquestion = \"What should be the minimum age of child labour?\"\ncontext = \"A minimum age of 14: Under s.48 and s.49 of the Child Rights Law 2019, a child under the age of 14 shall not be employed. If free compulsory education requires a child to be in school until after the age of 14, they shall also not be employed. If a child is employable under the Child Rights Law, they may engage in employment in accordance with existing labour laws.\"\n# Generate and print the result\nresult = generate_text(question, context)\n#print(context)\nprint(\"Generated Answer:\", result)","metadata":{"execution":{"iopub.status.busy":"2024-07-19T03:44:39.841699Z","iopub.execute_input":"2024-07-19T03:44:39.842398Z","iopub.status.idle":"2024-07-19T03:44:41.337821Z","shell.execute_reply.started":"2024-07-19T03:44:39.842369Z","shell.execute_reply":"2024-07-19T03:44:41.337016Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1797: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Generated Answer: The minimum age of child labour is 12\n","output_type":"stream"}]}]}